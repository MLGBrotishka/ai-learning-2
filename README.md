# Лабораторные работы №6-8

Выполнил студент группы М8О-406Б-21
Чапкин Владислав Вячеславович

## Описание

В данном репозитории представлены лабораторные работы №6, 7 и 8 по курсу "Методы, средства и технологии мультимедиа".

*   **Лабораторная работа №6:** Проведение исследований с моделями классификации (torchvision)
*   **Лабораторная работа №7:** Проведение исследований моделями семантической сегментации (segmentation\_models.pytorch)
*   **Лабораторная работа №8:** Проведение исследований моделями обнаружения и распознавания объектов (ultralytics YOLOv11)

## Структура репозитория

```
lab6.ipynb
lab7.ipynb
lab8.ipynb
README.md
```

## Краткие результаты по лабораторным работам

### Лабораторная работа №6: Исследование моделей классификации

**Задача:** Классификация изображений (на примере датасета Oxford-IIIT Pet).

**Решение:** Сравнение производительности предобученных моделей (ResNet50, Swin Transformer) и собственных упрощенных реализаций (SimpleCNN, VisionTransformerSimple) при дообучении/обучении с нуля с использованием унифицированных "улучшенных" настроек (аугментация, оптимизаторы, низкий LR).

**Сравнение производительности (метрики на валидационном наборе):**

|              | ResNet50 (Improved) | Swin (Improved) | SimpleCNN (Impl Improved) | ViT Simple (Impl Improved) |
|--------------|:-------------------:|:---------------:|:-------------------------:|:--------------------------:|
| Accuracy     | 0.9052              | 0.9270          | 0.1055                    | 0.0908                     |
| F1 Score     | 0.9027              | 0.9259          | 0.0695                    | 0.0739                     |
| mAP          | 0.9561              | 0.9694          | 0.0954                    | 0.0827                     |

**Выводы:**

1.  Предобученные модели (ResNet50, Swin) при дообучении с улучшенными настройками демонстрируют высокую производительность на задаче классификации изображений, достигая Accuracy выше 0.9.
2.  Собственные упрощенные реализации (SimpleCNN, VisionTransformerSimple), обученные с нуля с теми же "улучшенными" настройками, показывают существенно более низкие метрики (Accuracy около 0.1).
3.  Значительный разрыв в производительности объясняется прежде всего **отсутствием предобучения на крупном датасете** у собственных моделей. Предобучение позволяет моделям выучивать универсальные и мощные признаки, эффективно переносимые на новые задачи с ограниченным объемом данных.
4.  Дополнительным фактором является упрощенная архитектура собственных моделей по сравнению с полноразмерными ResNet50 и Swin.
5.  Следует отметить, что обучение собственных моделей проводилось с ограниченным числом эпох (до 10) для ускорения экспериментов, что также повлияло на их итоговую производительность по сравнению с моделями, обученными или дообученными на протяжении большего времени.

**Заключение по ЛР6:** Для задач классификации на датасетах ограниченного размера дообучение предобученных моделей является значительно более эффективным подходом по сравнению с обучением упрощенных моделей с нуля.

### Лабораторная работа №7: Исследование моделей семантической сегментации

**Задача:** Семантическая сегментация изображений (на примере датасета Oxford-IIIT Pet).

**:** Сравнение производительности предобученных моделей (Unet, Segformer) и собственных упрощенных реализаций (Simple UNet, Simple ViT) при дообучении/обучении с нуля с использованием унифицированных "улучшенных" настроек (аугментация, оптимизаторы, низкий LR).

**Сравнение производительности (метрики на валидационном наборе):**

| Метрика                     | Unet (improved) | Simple UNet (Impl improved) | Segformer (improved) | Simple ViT (Impl improved) |
|:----------------------------|:----------------|:----------------------------|:---------------------|:---------------------------|
| F1 Score (Weighted)         | 0.9887          | 0.8269                      | 0.9881               | 0.8639                     |
| mAP (mean IoU)              | 0.9752          | 0.6780                      | 0.9738               | 0.7378                     |
| Hamming Loss (Pixel Error)  | 0.0113          | 0.1686                      | 0.0119               | 0.1339                     |


**Выводы:**

1.  Предобученные модели (Unet, Segformer) при дообучении с улучшенными настройками достигают высокого качества сегментации (mAP около 0.97).
2.  Собственные упрощенные реализации (Simple UNet, Simple ViT), обученные с нуля с теми же "улучшенными" настройками, демонстрируют существенно более низкие метрики (mAP в диапазоне 0.67-0.73).
3.  Техники улучшения значительно увеличили точность моделей по сравнению с базовыми вариантами.
4.  Основной причиной значительного отставания собственных моделей является **отсутствие предобучения**, критически важное для задач сегментации на ограниченных данных.
5.  Ограниченное число эпох обучения (до 10) для собственных реализаций также существенно повлияло на их итоговые метрики.

**Заключение по ЛР7:** Высокое качество семантической сегментации на данном датасете достигается дообучением предобученных моделей.

### Лабораторная работа №8: Исследование моделей обнаружения и распознавания объектов

**Задача:** Обнаружение и распознавание объектов.

**Решение:** Сравнение производительности готовой модели из библиотеки (Ultralytics YOLOv8n) и собственной упрощенной реализации детектора, обученной на упрощенном датасете (с одним объектом).

**Сравнение производительности (метрика mAP@0.5):**

| Metric  | YOLOv8n (Baseline) | Custom Simple Detector (Baseline) |
|---------|:------------------:|:---------------------------------:|
| mAP@0.5 |       0.9849       |       0.7059                      |

**Выводы:**

1.  Готовая, полнофункциональная модель обнаружения объектов (YOLOv8n) демонстрирует высокую метрику mAP@0.5 (0.9849) на своей задаче.
2.  Собственная упрощенная модель детекции, разработанная для демонстрации базовых принципов и обученная на упрощенном датасете (один объект), показывает более низкий mAP@0.5 (0.7059).
3.  Разница в производительности обусловлена **кардинально разной сложностью моделей и решаемых задач**: YOLOv8n является комплексной моделью, разработанной для обнаружения множества объектов в сложных сценах с высокой точностью, тогда как собственная реализация представляет собой базовую структуру, способную детектировать один доминирующий объект.
4.  Ограниченное число эпох обучения (до 10) для собственной реализации также является фактором, влияющим на достигнутую точность.
5.  Несмотря на разрыв в метриках, собственная реализация демонстрирует базовые компоненты и принцип работы моделей обнаружения объектов. Даже при небольшом количестве эпох обучения собственная реализация демонстрирует хорошую точность обнаружения объектов.

**Заключение по ЛР8:** Для решения реальных задач обнаружения объектов требуются сложные, как правило, предобученные модели. Собственные упрощенные реализации могут служить для понимания архитектурных принципов, но не могут конкурировать по производительности с готовыми фреймворками при ограниченных ресурсах обучения.
